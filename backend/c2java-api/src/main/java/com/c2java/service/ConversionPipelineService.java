package com.c2java.service;

import com.c2java.domain.ConversionJob;
import com.c2java.domain.AnalysisResult;
import com.c2java.dto.CFileStructure;
import com.c2java.event.JobCreatedEvent;
import com.c2java.repository.ConversionJobRepository;
import com.c2java.repository.AnalysisResultRepository;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.scheduling.annotation.Async;
import org.springframework.stereotype.Service;
import org.springframework.transaction.annotation.Propagation;
import org.springframework.transaction.annotation.Transactional;

import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.*;

/**
 * ë³€í™˜ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì„œë¹„ìŠ¤
 * ì „ì²´ ë³€í™˜ í”„ë¡œì„¸ìŠ¤ë¥¼ í†µí•© ê´€ë¦¬
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class ConversionPipelineService {

    private final ConversionJobRepository jobRepository;
    private final AnalysisResultRepository analysisRepository;
    private final CFileAnalyzerService analyzerService;
    private final CodeConverterService converterService;
    private final AirflowDagService airflowDagService;
    private final AirflowApiService airflowApiService;
    private final GradleBuildService buildService;
    private final TestRunnerService testService;
    private final ObjectMapper objectMapper;
    private final com.c2java.repository.FileConversionResultRepository fileResultRepository;

    /**
     * Job ê°ì²´ë¡œ ë³€í™˜ ì‹œì‘
     */
    public void startConversionWithJob(ConversionJob job, List<Path> sourceFiles) {
        log.info("ğŸš€ [AIRFLOW] Starting pipeline for job: {}", job.getJobId());
        
        try {
            job.appendLog("ë³€í™˜ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤...");
            log.info("âœ… [AIRFLOW] appendLog succeeded");
            
            // 1. Airflow DAG ìƒì„± (íŒŒì¼ ê°œìˆ˜ ì „ë‹¬)
            job.setStatus(ConversionJob.JobStatus.PENDING);
            job.updateProgress("INITIALIZE", 5);
            jobRepository.save(job);
            
            int fileCount = sourceFiles != null ? sourceFiles.size() : 0;
            log.info("Creating DAG for {} files", fileCount);
            job.appendLog(String.format("ì´ %dê°œì˜ íŒŒì¼ì„ ë³€í™˜í•©ë‹ˆë‹¤.", fileCount));
            
            try {
                String dagId = airflowDagService.createConversionDag(job, fileCount);
                job.setAirflowDagId(dagId);
                job.appendLog("âœ… Airflow DAGê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: " + dagId);
                jobRepository.save(job);
                log.info("âœ… DAG created successfully: {}", dagId);
            } catch (Exception e) {
                log.error("âŒ Failed to create DAG", e);
                job.appendLog("âŒ DAG ìƒì„± ì‹¤íŒ¨: " + e.getMessage());
                job.appendLog("ìƒì„¸: " + e.getClass().getSimpleName());
                throw e;
            }
            
            // DAGê°€ Airflowì— ë“±ë¡ë  ë•Œê¹Œì§€ ëŒ€ê¸° (ìµœëŒ€ 90ì´ˆ)
            job.appendLog("â³ Airflowê°€ DAGë¥¼ ì¸ì‹í•˜ëŠ” ì¤‘...");
            jobRepository.save(job);
            
            boolean dagRegistered = false;
            for (int i = 0; i < 30; i++) {  // 30ë²ˆ ì‹œë„ (3ì´ˆë§ˆë‹¤ = ìµœëŒ€ 90ì´ˆ)
                try {
                    Thread.sleep(3000);  // 3ì´ˆ ëŒ€ê¸°
                    // DAG ì¡´ì¬ ì—¬ë¶€ë¥¼ ì²´í¬í•˜ëŠ” ê°„ë‹¨í•œ API í˜¸ì¶œ
                    try {
                        Map<String, Object> dagInfo = airflowApiService.getDagInfo(job.getAirflowDagId());
                        if (dagInfo != null && dagInfo.containsKey("dag_id")) {
                            dagRegistered = true;
                            log.info("âœ… [AIRFLOW] DAG registered after {} seconds", (i + 1) * 3);
                            job.appendLog(String.format("âœ… DAG ë“±ë¡ ì™„ë£Œ (%dì´ˆ ì†Œìš”)", (i + 1) * 3));
                            jobRepository.save(job);
                            break;
                        }
                    } catch (Exception e) {
                        // 404ëŠ” ì•„ì§ ë“±ë¡ ì•ˆ ëœ ê²ƒ, ê³„ì† ëŒ€ê¸°
                        if (i % 5 == 0) {  // 15ì´ˆë§ˆë‹¤ ë¡œê·¸
                            log.info("â³ [AIRFLOW] Waiting for DAG registration... ({}s elapsed)", (i + 1) * 3);
                        }
                        if (i == 29) {  // ë§ˆì§€ë§‰ ì‹œë„
                            log.warn("âš ï¸ [AIRFLOW] DAG not registered after 90 seconds");
                        }
                    }
                } catch (InterruptedException e) {
                    Thread.currentThread().interrupt();
                    throw new RuntimeException("Interrupted while waiting for DAG registration", e);
                }
            }
            
            if (!dagRegistered) {
                job.appendLog("âš ï¸ DAG ë“±ë¡ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼ (90ì´ˆ), íŠ¸ë¦¬ê±°ë¥¼ ì‹œë„í•©ë‹ˆë‹¤...");
                jobRepository.save(job);
            }
            
            // 2. DAG íŠ¸ë¦¬ê±°
            Map<String, Object> config = Map.of(
                    "job_id", job.getJobId().toString(),
                    "target_language", job.getTargetLanguage(),
                    "source_files", sourceFiles.stream().map(Path::toString).toList()
            );
            
            job.appendLog("Airflow ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...");
            
            try {
                Map<String, Object> dagRun = airflowApiService.triggerDag(job.getAirflowDagId(), config);
                job.setAirflowRunId((String) dagRun.get("dag_run_id"));
                job.appendLog("âœ… ì›Œí¬í”Œë¡œìš°ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤: " + dagRun.get("dag_run_id"));
                jobRepository.save(job);
                log.info("âœ… Airflow DAG triggered: {} / {}", job.getAirflowDagId(), dagRun.get("dag_run_id"));
            } catch (Exception e) {
                log.error("âŒ Failed to trigger DAG", e);
                job.appendLog("âŒ ì›Œí¬í”Œë¡œìš° ì‹œì‘ ì‹¤íŒ¨: " + e.getMessage());
                job.appendLog("ìƒì„¸: " + e.getClass().getSimpleName());
                throw e;
            }
            
        } catch (Exception e) {
            log.error("âŒ Pipeline start failed for job: {}", job.getJobId(), e);
            job.appendLog("");
            job.appendLog("âŒ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹¤íŒ¨");
            job.appendLog("ì˜¤ë¥˜ ìœ í˜•: " + e.getClass().getSimpleName());
            job.appendLog("ì˜¤ë¥˜ ë©”ì‹œì§€: " + e.getMessage());
            if (e.getCause() != null) {
                job.appendLog("ê·¼ë³¸ ì›ì¸: " + e.getCause().getMessage());
            }
            job.markFailed("íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹¤íŒ¨: " + e.getMessage());
            jobRepository.save(job);
        }
    }
    

    /**
     * íŒŒì¼ ë¶„ì„ ë‹¨ê³„ (Airflow Taskì—ì„œ í˜¸ì¶œ)
     */
    @Transactional
    public Map<String, Object> analyzeStep(String jobId) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        // ì·¨ì†Œ ìƒíƒœ í™•ì¸
        if (job.getStatus() == ConversionJob.JobStatus.CANCELLED) {
            log.info("Job {} is cancelled, skipping analyze step", jobId);
            throw new RuntimeException("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.");
        }
        
        try {
            job.setStatus(ConversionJob.JobStatus.ANALYZING);
            job.updateProgress("ANALYZE", 10);
            job.appendLog("íŒŒì¼ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...");
            jobRepository.save(job);
            
            // ì†ŒìŠ¤ íŒŒì¼ ë¡œë“œ
            List<Path> sourceFiles = loadSourceFiles(job);
            
            // ê° íŒŒì¼ ë¶„ì„
            int functionCount = 0;
            int structCount = 0;
            int sqlCount = 0;
            
            for (Path file : sourceFiles) {
                CFileStructure structure = analyzerService.analyzeFile(file);
                
                // ë¶„ì„ ê²°ê³¼ ì €ì¥
                AnalysisResult analysis = AnalysisResult.builder()
                        .jobId(jobId)
                        .sourceFile(file.getFileName().toString())
                        .fileType(structure.getFileType())
                        .functions(toJson(structure.getFunctions()))
                        .structs(toJson(structure.getStructs()))
                        .enums(toJson(structure.getEnums()))
                        .sqlQueries(toJson(structure.getSqlQueries()))
                        .includes(toJson(structure.getIncludes()))
                        .defines(toJson(structure.getDefines()))
                        .lineCount(structure.getLineCount())
                        .functionCount(structure.getFunctions().size())
                        .structCount(structure.getStructs().size())
                        .build();
                
                analysisRepository.save(analysis);
                
                functionCount += structure.getFunctions().size();
                structCount += structure.getStructs().size();
                sqlCount += structure.getSqlQueries().size();
            }
            
            // ì‘ì—… ì •ë³´ ì—…ë°ì´íŠ¸
            job.setFunctionCount(functionCount);
            job.setStructCount(structCount);
            job.setSqlCount(sqlCount);
            job.updateProgress("ANALYZE", 25);
            jobRepository.save(job);
            
            Map<String, Object> result = new HashMap<>();
            result.put("success", true);
            result.put("function_count", functionCount);
            result.put("struct_count", structCount);
            result.put("sql_count", sqlCount);
            
            return result;
            
        } catch (Exception e) {
            log.error("Analysis failed", e);
            // ì·¨ì†Œëœ ê²½ìš°ëŠ” ì‹¤íŒ¨ë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ
            if (job.getStatus() != ConversionJob.JobStatus.CANCELLED) {
                job.appendLog("ë¶„ì„ ì‹¤íŒ¨: " + e.getMessage());
                job.markFailed("ë¶„ì„ ì‹¤íŒ¨: " + e.getMessage());
                jobRepository.save(job);
            }
            throw new RuntimeException(e);
        }
    }

    /**
     * ì½”ë“œ ë³€í™˜ ë‹¨ê³„
     */
    @Transactional
    public Map<String, Object> convertStep(String jobId) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        // ì·¨ì†Œ ìƒíƒœ í™•ì¸
        if (job.getStatus() == ConversionJob.JobStatus.CANCELLED) {
            log.info("Job {} is cancelled, skipping convert step", jobId);
            throw new RuntimeException("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.");
        }
        
        try {
            job.setStatus(ConversionJob.JobStatus.CONVERTING);
            job.updateProgress("CONVERT", 30);
            job.appendLog("ì½”ë“œ ë³€í™˜ì„ ì‹œì‘í•©ë‹ˆë‹¤...");
            jobRepository.save(job);
            
            // ì†ŒìŠ¤ íŒŒì¼ ë¡œë“œ
            List<Path> sourceFiles = loadSourceFiles(job);
            job.appendLog(String.format("%dê°œ íŒŒì¼ì„ Javaë¡œ ë³€í™˜í•©ë‹ˆë‹¤...", sourceFiles.size()));
            jobRepository.save(job);
            
            // ì·¨ì†Œ ìƒíƒœ ì¬í™•ì¸
            job = jobRepository.findByJobId(UUID.fromString(jobId))
                    .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
            if (job.getStatus() == ConversionJob.JobStatus.CANCELLED) {
                throw new RuntimeException("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.");
            }
            
            // Java ì½”ë“œ ìƒì„±
            Map<String, String> generatedFiles = converterService.convertCFiles(job, sourceFiles);
            job.appendLog(String.format("%dê°œì˜ Java íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.", generatedFiles.size()));
            jobRepository.save(job);
            
            // ìƒì„±ëœ íŒŒì¼ ì €ì¥
            Path outputPath = Paths.get("/tmp/c2java/output/" + jobId);
            Files.createDirectories(outputPath);
            
            for (Map.Entry<String, String> entry : generatedFiles.entrySet()) {
                Path filePath = outputPath.resolve(entry.getKey());
                Files.createDirectories(filePath.getParent());
                Files.writeString(filePath, entry.getValue());
            }
            
            job.setGeneratedFileCount(generatedFiles.size());
            job.setOutputPath(outputPath.toString());
            job.updateProgress("CONVERT", 60);
            jobRepository.save(job);
            
            Map<String, Object> result = new HashMap<>();
            result.put("success", true);
            result.put("generated_files", generatedFiles.size());
            result.put("output_path", outputPath.toString());
            
            return result;
            
        } catch (Exception e) {
            log.error("Conversion failed", e);
            // ì·¨ì†Œëœ ê²½ìš°ëŠ” ì‹¤íŒ¨ë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ
            if (job.getStatus() != ConversionJob.JobStatus.CANCELLED) {
                job.appendLog("ë³€í™˜ ì‹¤íŒ¨: " + e.getMessage());
                job.markFailed("ë³€í™˜ ì‹¤íŒ¨: " + e.getMessage());
                jobRepository.save(job);
            }
            throw new RuntimeException(e);
        }
    }

    /**
     * ì»´íŒŒì¼ ë‹¨ê³„
     */
    @Transactional
    public Map<String, Object> compileStep(String jobId) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        // ì·¨ì†Œ ìƒíƒœ í™•ì¸
        if (job.getStatus() == ConversionJob.JobStatus.CANCELLED) {
            log.info("Job {} is cancelled, skipping compile step", jobId);
            throw new RuntimeException("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.");
        }
        
        try {
            job.setStatus(ConversionJob.JobStatus.COMPILING);
            job.updateProgress("COMPILE", 65);
            job.appendLog("ì»´íŒŒì¼ì„ ì‹œì‘í•©ë‹ˆë‹¤...");
            jobRepository.save(job);
            
            Path projectPath = Paths.get(job.getOutputPath());
            Map<String, Object> buildResult = buildService.buildProject(projectPath);
            
            boolean success = (boolean) buildResult.get("success");
            job.setCompileSuccess(success);
            
            if (success) {
                job.appendLog("ì»´íŒŒì¼ì´ ì„±ê³µí–ˆìŠµë‹ˆë‹¤.");
            } else {
                List<String> errors = (List<String>) buildResult.get("errors");
                job.setCompileErrors(String.join("\n", errors));
                job.appendLog("ì»´íŒŒì¼ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: " + errors.size() + "ê°œ");
            }
            
            job.updateProgress("COMPILE", 80);
            jobRepository.save(job);
            
            return buildResult;
            
        } catch (Exception e) {
            log.error("Compilation failed", e);
            // ì·¨ì†Œëœ ê²½ìš°ëŠ” ì‹¤íŒ¨ë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ
            if (job.getStatus() != ConversionJob.JobStatus.CANCELLED) {
                job.appendLog("ì»´íŒŒì¼ ì‹¤íŒ¨: " + e.getMessage());
                job.setCompileSuccess(false);
                job.setCompileErrors(e.getMessage());
                jobRepository.save(job);
            }
            throw new RuntimeException(e);
        }
    }

    /**
     * í…ŒìŠ¤íŠ¸ ë‹¨ê³„
     */
    @Transactional
    public Map<String, Object> testStep(String jobId) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        // ì·¨ì†Œ ìƒíƒœ í™•ì¸
        if (job.getStatus() == ConversionJob.JobStatus.CANCELLED) {
            log.info("Job {} is cancelled, skipping test step", jobId);
            throw new RuntimeException("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.");
        }
        
        try {
            job.setStatus(ConversionJob.JobStatus.TESTING);
            job.updateProgress("TEST", 85);
            job.appendLog("í…ŒìŠ¤íŠ¸ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...");
            jobRepository.save(job);
            
            Path projectPath = Paths.get(job.getOutputPath());
            Map<String, Object> testResult = testService.runTests(projectPath);
            
            boolean success = (boolean) testResult.get("success");
            job.setTestSuccess(success);
            job.setTestResults(testResult.toString());
            
            if (success) {
                job.appendLog("ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í–ˆìŠµë‹ˆë‹¤.");
            } else {
                job.appendLog("ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.");
            }
            
            job.updateProgress("TEST", 95);
            jobRepository.save(job);
            
            return testResult;
            
        } catch (Exception e) {
            log.error("Testing failed", e);
            // ì·¨ì†Œëœ ê²½ìš°ëŠ” ì‹¤íŒ¨ë¡œ í‘œì‹œí•˜ì§€ ì•ŠìŒ
            if (job.getStatus() != ConversionJob.JobStatus.CANCELLED) {
                job.appendLog("í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: " + e.getMessage());
                job.setTestSuccess(false);
                job.setTestResults("í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: " + e.getMessage());
                jobRepository.save(job);
            }
            throw new RuntimeException(e);
        }
    }

    /**
     * ì‘ì—… ìƒíƒœ ì¡°íšŒ (Airflow ìƒíƒœ í¬í•¨)
     */
    @Transactional(readOnly = true)
    public Map<String, Object> getJobStatus(String jobId) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        Map<String, Object> status = new HashMap<>();
        status.put("jobId", job.getJobId());
        status.put("jobName", job.getJobName());
        status.put("status", job.getStatus());
        status.put("currentStage", job.getCurrentStage());
        status.put("progress", job.getProgress());
        status.put("targetLanguage", job.getTargetLanguage());
        
        // Airflow ìƒíƒœ
        if (job.getAirflowDagId() != null && job.getAirflowRunId() != null) {
            try {
                Map<String, Object> dagRunStatus = airflowApiService.getDagRunStatus(
                        job.getAirflowDagId(), 
                        job.getAirflowRunId()
                );
                status.put("airflowStatus", dagRunStatus);
                
                // Task ìƒíƒœë“¤
                Map<String, Object> taskInstances = airflowApiService.getAllTaskInstances(
                        job.getAirflowDagId(), 
                        job.getAirflowRunId()
                );
                status.put("tasks", taskInstances.get("task_instances"));
                
            } catch (Exception e) {
                log.warn("Failed to get Airflow status", e);
                status.put("airflowStatus", Map.of("state", "unavailable"));
            }
        }
        
        // ë¶„ì„ ê²°ê³¼
        List<AnalysisResult> analysisResults = analysisRepository.findByJobId(jobId);
        status.put("analysisResults", analysisResults);
        
        // í†µê³„
        status.put("functionCount", job.getFunctionCount());
        status.put("structCount", job.getStructCount());
        status.put("sqlCount", job.getSqlCount());
        status.put("generatedFileCount", job.getGeneratedFileCount());
        status.put("compileSuccess", job.getCompileSuccess());
        status.put("testSuccess", job.getTestSuccess());
        
        return status;
    }

    /**
     * ì†ŒìŠ¤ íŒŒì¼ ë¡œë“œ
     */
    private List<Path> loadSourceFiles(ConversionJob job) throws IOException {
        Path sourcePath = Paths.get(job.getSourceFilePath());
        
        if (Files.isDirectory(sourcePath)) {
            return Files.list(sourcePath)
                    .filter(p -> p.toString().endsWith(".c") || 
                                p.toString().endsWith(".h") || 
                                p.toString().endsWith(".pc"))
                    .toList();
        } else {
            return List.of(sourcePath);
        }
    }

    /**
     * JSON ë³€í™˜
     */
    private String toJson(Object obj) {
        try {
            return objectMapper.writeValueAsString(obj);
        } catch (Exception e) {
            return "[]";
        }
    }

    // ============= íŒŒì¼ë³„ ê°œë³„ ì²˜ë¦¬ ë©”ì„œë“œ =============

    /**
     * Jobì˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ
     */
    @Transactional(readOnly = true)
    public Map<String, Object> getJobFiles(String jobId) {
        // sourcePathë§Œ ì¡°íšŒ (LOB í•„ë“œ ì ‘ê·¼ ë°©ì§€)
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        String sourcePathStr = job.getSourcePath();
        
        try {
            Path sourcePath = Paths.get(sourcePathStr);
            List<String> files = new ArrayList<>();
            
            if (Files.exists(sourcePath)) {
                Files.walk(sourcePath)
                        .filter(Files::isRegularFile)
                        .filter(p -> p.toString().endsWith(".c") || p.toString().endsWith(".h"))
                        .forEach(p -> files.add(p.toString()));
            }
            
            return Map.of(
                    "jobId", jobId,
                    "files", files,
                    "fileCount", files.size()
            );
        } catch (IOException e) {
            log.error("Failed to get file list for job: {}", jobId, e);
            return Map.of("files", Collections.emptyList(), "error", e.getMessage());
        }
    }

    /**
     * íŒŒì¼ë³„ ë¶„ì„
     */
    @Transactional
    public Map<String, Object> analyzeFile(String jobId, String fileName) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        // íŒŒì¼ ê²°ê³¼ ë ˆì½”ë“œ ì¡°íšŒ ë˜ëŠ” ìƒì„±
        com.c2java.domain.FileConversionResult fileResult = fileResultRepository
                .findByJobIdAndSourceFileName(job.getJobId(), fileName);
        
        if (fileResult == null) {
            fileResult = com.c2java.domain.FileConversionResult.builder()
                    .jobId(job.getJobId())
                    .sourceFileName(fileName)
                    .status(com.c2java.domain.FileConversionResult.FileStatus.ANALYZING)
                    .currentStage(com.c2java.domain.FileConversionResult.FileStage.ANALYZE)
                    .progress(10)
                    .build();
        } else {
            fileResult.setStatus(com.c2java.domain.FileConversionResult.FileStatus.ANALYZING);
            fileResult.setCurrentStage(com.c2java.domain.FileConversionResult.FileStage.ANALYZE);
            fileResult.setProgress(10);
        }
        
        fileResult.appendLog("ğŸ“Š íŒŒì¼ ë¶„ì„ ì‹œì‘: " + fileName);
        fileResultRepository.save(fileResult);
        
        try {
            // íŒŒì¼ ì°¾ê¸°
            Path sourcePath = Paths.get(job.getSourcePath());
            Path filePath = Files.walk(sourcePath)
                    .filter(p -> p.getFileName().toString().equals(fileName))
                    .findFirst()
                    .orElseThrow(() -> new IllegalArgumentException("File not found: " + fileName));
            
            fileResult.setSourceFilePath(filePath.toString());
            
            // ë¶„ì„ ì‹¤í–‰
            CFileStructure structure = analyzerService.analyzeFile(filePath);
            
            // ë¶„ì„ ê²°ê³¼ ì €ì¥
            fileResult.setAnalyzeResult(toJson(Map.of(
                    "functions", structure.getFunctions().size(),
                    "structs", structure.getStructs().size(),
                    "lines", structure.getLineCount()
            )));
            fileResult.updateStage(
                    com.c2java.domain.FileConversionResult.FileStage.ANALYZE,
                    com.c2java.domain.FileConversionResult.FileStatus.ANALYZING,
                    25
            );
            fileResult.appendLog("âœ… ë¶„ì„ ì™„ë£Œ: í•¨ìˆ˜ " + structure.getFunctions().size() + 
                               "ê°œ, êµ¬ì¡°ì²´ " + structure.getStructs().size() + "ê°œ");
            fileResultRepository.save(fileResult);
            
            return Map.of(
                    "status", "success",
                    "file", fileName,
                    "structure", structure
            );
            
        } catch (Exception e) {
            log.error("íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {}", fileName, e);
            fileResult.markFailed("ë¶„ì„ ì‹¤íŒ¨: " + e.getMessage());
            fileResultRepository.save(fileResult);
            
            return Map.of(
                    "status", "failed",
                    "file", fileName,
                    "error", e.getMessage()
            );
        }
    }

    /**
     * íŒŒì¼ë³„ ë³€í™˜
     */
    @Transactional
    public Map<String, Object> convertFile(String jobId, String fileName) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        com.c2java.domain.FileConversionResult fileResult = fileResultRepository
                .findByJobIdAndSourceFileName(job.getJobId(), fileName);
        
        if (fileResult == null) {
            throw new IllegalStateException("íŒŒì¼ ë¶„ì„ì´ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤: " + fileName);
        }
        
        fileResult.setStatus(com.c2java.domain.FileConversionResult.FileStatus.CONVERTING);
        fileResult.setCurrentStage(com.c2java.domain.FileConversionResult.FileStage.CONVERT);
        fileResult.setProgress(40);
        fileResult.appendLog("ğŸ”„ Java ë³€í™˜ ì‹œì‘: " + fileName);
        fileResultRepository.save(fileResult);
        
        try {
            Path filePath = Paths.get(fileResult.getSourceFilePath());
            
            // ë³€í™˜ ë¡œê·¸ë¥¼ ê¸°ë¡í•˜ê¸° ìœ„í•œ StringBuilder ìƒì„±
            StringBuilder conversionLog = new StringBuilder();
            conversionLog.append("\nğŸ“ ì½”ë“œ ë³€í™˜ ë¡œê·¸\n");
            conversionLog.append("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");
            
            // ë³€í™˜ ì‹¤í–‰ (ë¡œê·¸ í¬í•¨)
            Map<String, String> generatedFiles = converterService.convertCFiles(
                    job,
                    List.of(filePath),
                    conversionLog
            );
            
            // ë³€í™˜ ë¡œê·¸ë¥¼ FileConversionResultì— ì¶”ê°€
            if (conversionLog.length() > 0) {
                fileResult.appendLog(conversionLog.toString());
            }
            
            // ìƒì„±ëœ íŒŒì¼ ê²½ë¡œ ì €ì¥
            String javaFile = generatedFiles.keySet().iterator().next();
            fileResult.setOutputFilePath(javaFile);
            fileResult.setConvertResult(toJson(Map.of(
                    "generatedFiles", generatedFiles.keySet(),
                    "linesConverted", generatedFiles.values().iterator().next().split("\n").length
            )));
            fileResult.updateStage(
                    com.c2java.domain.FileConversionResult.FileStage.CONVERT,
                    com.c2java.domain.FileConversionResult.FileStatus.CONVERTING,
                    55
            );
            fileResult.appendLog("âœ… ë³€í™˜ ì™„ë£Œ: " + javaFile);
            fileResultRepository.save(fileResult);
            
            return Map.of(
                    "status", "success",
                    "file", fileName,
                    "output", javaFile
            );
            
        } catch (Exception e) {
            log.error("íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: {}", fileName, e);
            fileResult.markFailed("ë³€í™˜ ì‹¤íŒ¨: " + e.getMessage());
            fileResultRepository.save(fileResult);
            
            return Map.of(
                    "status", "failed",
                    "file", fileName,
                    "error", e.getMessage()
            );
        }
    }

    /**
     * íŒŒì¼ë³„ ì»´íŒŒì¼
     */
    @Transactional
    public Map<String, Object> compileFile(String jobId, String fileName) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        com.c2java.domain.FileConversionResult fileResult = fileResultRepository
                .findByJobIdAndSourceFileName(job.getJobId(), fileName);
        
        if (fileResult == null || fileResult.getOutputFilePath() == null) {
            throw new IllegalStateException("íŒŒì¼ ë³€í™˜ì´ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•©ë‹ˆë‹¤: " + fileName);
        }
        
        fileResult.setStatus(com.c2java.domain.FileConversionResult.FileStatus.COMPILING);
        fileResult.setCurrentStage(com.c2java.domain.FileConversionResult.FileStage.COMPILE);
        fileResult.setProgress(70);
        fileResult.appendLog("ğŸ”¨ ì»´íŒŒì¼ ì‹œì‘: " + fileName);
        fileResultRepository.save(fileResult);
        
        try {
            Path projectPath = Paths.get(job.getOutputPath());
            Map<String, Object> buildResult = buildService.buildProject(projectPath);
            
            boolean success = (boolean) buildResult.get("success");
            fileResult.setCompileSuccess(success);
            
            if (!success) {
                List<String> errors = (List<String>) buildResult.get("errors");
                fileResult.setCompileErrors(String.join("\n", errors));
                fileResult.appendLog("âš ï¸ ì»´íŒŒì¼ ì˜¤ë¥˜: " + errors.size() + "ê°œ");
            } else {
                fileResult.appendLog("âœ… ì»´íŒŒì¼ ì™„ë£Œ");
            }
            
            fileResult.updateStage(
                    com.c2java.domain.FileConversionResult.FileStage.COMPILE,
                    com.c2java.domain.FileConversionResult.FileStatus.COMPILING,
                    80
            );
            fileResultRepository.save(fileResult);
            
            return Map.of(
                    "status", success ? "success" : "failed",
                    "file", fileName,
                    "compileSuccess", success,
                    "errors", buildResult.get("errors")
            );
            
        } catch (Exception e) {
            log.error("íŒŒì¼ ì»´íŒŒì¼ ì‹¤íŒ¨: {}", fileName, e);
            fileResult.markFailed("ì»´íŒŒì¼ ì‹¤íŒ¨: " + e.getMessage());
            fileResultRepository.save(fileResult);
            
            return Map.of(
                    "status", "failed",
                    "file", fileName,
                    "error", e.getMessage()
            );
        }
    }

    /**
     * íŒŒì¼ë³„ í…ŒìŠ¤íŠ¸
     */
    @Transactional
    public Map<String, Object> testFile(String jobId, String fileName) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        com.c2java.domain.FileConversionResult fileResult = fileResultRepository
                .findByJobIdAndSourceFileName(job.getJobId(), fileName);
        
        if (fileResult == null || !Boolean.TRUE.equals(fileResult.getCompileSuccess())) {
            throw new IllegalStateException("ì»´íŒŒì¼ì´ ë¨¼ì € ì„±ê³µí•´ì•¼ í•©ë‹ˆë‹¤: " + fileName);
        }
        
        fileResult.setStatus(com.c2java.domain.FileConversionResult.FileStatus.TESTING);
        fileResult.setCurrentStage(com.c2java.domain.FileConversionResult.FileStage.TEST);
        fileResult.setProgress(90);
        fileResult.appendLog("ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œì‘: " + fileName);
        fileResultRepository.save(fileResult);
        
        try {
            Path projectPath = Paths.get(job.getOutputPath());
            Map<String, Object> testResult = testService.runTests(projectPath);
            
            boolean success = (boolean) testResult.get("success");
            fileResult.setTestSuccess(success);
            fileResult.setTestResults(toJson(testResult));
            
            if (success) {
                fileResult.markCompleted();
                fileResult.appendLog("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ - ëª¨ë“  ë‹¨ê³„ ì„±ê³µ!");
            } else {
                fileResult.appendLog("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨");
                fileResult.setProgress(95);
            }
            
            fileResultRepository.save(fileResult);
            
            return Map.of(
                    "status", success ? "success" : "failed",
                    "file", fileName,
                    "testSuccess", success,
                    "results", testResult
            );
            
        } catch (Exception e) {
            log.error("íŒŒì¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {}", fileName, e);
            fileResult.markFailed("í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: " + e.getMessage());
            fileResultRepository.save(fileResult);
            
            return Map.of(
                    "status", "failed",
                    "file", fileName,
                    "error", e.getMessage()
            );
        }
    }

    /**
     * íŒŒì¼ë³„ ë³€í™˜ ê²°ê³¼ ëª©ë¡
     */
    public List<Map<String, Object>> getFileResults(String jobId) {
        List<com.c2java.domain.FileConversionResult> results = fileResultRepository
                .findByJobIdOrderByCreatedAt(UUID.fromString(jobId));
        
        return results.stream()
                .map(r -> Map.of(
                        "fileName", r.getSourceFileName(),
                        "status", r.getStatus().toString(),
                        "stage", r.getCurrentStage().toString(),
                        "progress", r.getProgress(),
                        "compileSuccess", r.getCompileSuccess() != null ? r.getCompileSuccess() : false,
                        "testSuccess", r.getTestSuccess() != null ? r.getTestSuccess() : false,
                        "outputFile", r.getOutputFilePath() != null ? r.getOutputFilePath() : "",
                        "completedAt", (Object)(r.getCompletedAt() != null ? r.getCompletedAt().toString() : ""),
                        "errorMessage", (Object)(r.getErrorMessage() != null ? r.getErrorMessage() : "")
                ))
                .map(m -> (Map<String, Object>) m)
                .toList();
    }

    /**
     * ì™„ë£Œëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
     */
    public byte[] getConvertedFile(String jobId, String fileName) {
        com.c2java.domain.FileConversionResult fileResult = fileResultRepository
                .findByJobIdAndSourceFileName(UUID.fromString(jobId), fileName);
        
        if (fileResult == null || fileResult.getOutputFilePath() == null) {
            throw new IllegalArgumentException("ë³€í™˜ëœ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: " + fileName);
        }
        
        try {
            Path outputPath = Paths.get(fileResult.getOutputFilePath());
            return Files.readAllBytes(outputPath);
        } catch (IOException e) {
            log.error("íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {}", fileName, e);
            throw new RuntimeException("íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: " + e.getMessage());
        }
    }

    /**
     * ì „ì²´ ì‘ì—… ì™„ë£Œ ì²˜ë¦¬
     */
    @Transactional
    public Map<String, Object> finalizeJob(String jobId) {
        ConversionJob job = jobRepository.findByJobId(UUID.fromString(jobId))
                .orElseThrow(() -> new IllegalArgumentException("Job not found: " + jobId));
        
        // ëª¨ë“  íŒŒì¼ ê²°ê³¼ í™•ì¸
        List<com.c2java.domain.FileConversionResult> fileResults = fileResultRepository
                .findByJobIdOrderByCreatedAt(job.getJobId());
        
        long completedCount = fileResults.stream()
                .filter(r -> r.getStatus() == com.c2java.domain.FileConversionResult.FileStatus.COMPLETED)
                .count();
        
        long failedCount = fileResults.stream()
                .filter(r -> r.getStatus() == com.c2java.domain.FileConversionResult.FileStatus.FAILED)
                .count();
        
        if (failedCount > 0) {
            job.setStatus(ConversionJob.JobStatus.FAILED);
            job.appendLog(String.format("âŒ ì¼ë¶€ íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: %dê°œ ì„±ê³µ, %dê°œ ì‹¤íŒ¨", 
                                       completedCount, failedCount));
        } else {
            job.setStatus(ConversionJob.JobStatus.COMPLETED);
            job.updateProgress("COMPLETE", 100);
            job.appendLog(String.format("ğŸ‰ ì „ì²´ ë³€í™˜ ì™„ë£Œ: %dê°œ íŒŒì¼ ì„±ê³µ!", completedCount));
        }
        
        jobRepository.save(job);
        
        return Map.of(
                "status", "success",
                "completedFiles", completedCount,
                "failedFiles", failedCount,
                "totalFiles", fileResults.size()
        );
    }
}
